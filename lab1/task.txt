Виконати наступне: 
1) Завантажити дані, вивести назви колонок і розмір датасета
2) Опрацювати пропуски (по можливості заповнити їх або видалити)
3) Візуалізувати дані: побудувати графік (heatmap), що відображає кореляції
ознак між собою і з цільовою змінною (розміткою); побудувати гістограми
розподілу ознак і boxplot-и ознак відносно цільової змінної (якщо ознак занадто багато
обмежитися декількома)
4) Нормалізувати дані
5) Провести навчання наступних класифікаторів:
kNN
дерево прийняття рішень
SVM
Random Forest
AdaBoost
Підібрати оптимальні параметри
• для kNN
• для SVM за допомогою GridSearch підібрати оптимальні «C» і «gamma»
Серед обраних оптимальних моделей кожного класу вибрати найкращу.
Відобразити
sklearn.metrics.classification_report і sklearn.metrics.confusion_matrix

Як звіт – робочий код в Jupyter notebook заливаєте на свій репозиторій на
https://github.com/. Лінк - як відповідь до завдання. 

Максимальний бал – 10, 6 за роботу + 4 захист.
Deadline 5.11.22, після цього терміну максимальний бал зменшується на 1 кожні 2 тижні  (захист роботи можна проводити ще протягом 2х тижнів після дедлайна)


Дані можна брати тут:
https://www.kaggle.com/datasets

https://archive.ics.uci.edu/ml/index

Обов’язкова вимога – унікальність даних (датасети не повинні повторюватись), обраний
датасет заносите в табличку (посилання Lab 1, Datasets, 2022), попередньо перевіривши, що його ще ніхто не обрав.
Також дані, що розглядалися на практичних брати не слід (Іриси, Титанік, Wine, MNIST(рукописні цифри)).
