1. Зниження розмірності і візуалізація даних
Застосуйте методи зниження розмірності sklearn.decomposition.PCA і sklearn.manifold.TSNE для візуалізації даних, з якими ви працювали в лабораторній № 1 (знижуючи розмірність до двох). Візуалізуйте результат.
2. Кластерний аналіз
1) За допомогою алгоритму k-means зробіть квантування зображення (видалення візуально надлишкової інформації) з глибиною 64, 32, 16 та 8 рівнів для будь-якого обраного самостійно зображення. Приклад: https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html
3. Обробка та класифікація текстових даних
Завантажте набір текстових даних (з мітками класів). Проведіть передобробку даних (видаліть стоп-слова, пунктуацію), за допомогою wordcloud зробіть візуалізацію найбільш поширених слів або n-gram у кожному класі. Векторизуйте тексти (наприклад за допомогою sklearn.feature_extraction.text.TfidfVectorizer). Проведіть класифікацію текстових даних, зробіть оцінку якості. 
Текстові дані для аналізу можна обирати тут:
https://analyticsindiamag.com/10-open-source-datasets-for-text-classification
https://www.ics.uci.edu/~smyth/courses/cs175/text_data_sets.html
https://medium.com/@ODSC/20-open-datasets-for-natural-language-processing-538fbfaf8e38
https://odsc.medium.com/20-open-datasets-for-natural-language-processing-538fbfaf8e38
https://imerit.net/blog/25-best-nlp-datasets-for-machine-learning-all-pbm/
https://www.kaggle.com/
або з будь-якого іншого джерела за вашим вибором
(в разі великої кількості класів достатньо залишити 2-3)

Датасет IMDB Movie Review Sentiment classification не обирайте

Як звіт – робочий код в Jupyter notebook заливаєте на свій репозиторій на https://github.com/.
Лінк відправляєте як відповідь до цього завдання.
Максимальний бал – 10, 6 за роботу + 4 захист.
Deadline 19.11.22 (захист роботи можна проводити ще протягм 2х тижнів після дедлайна), після цього терміну максимальний бал зменшується на 1 кожні 2 тижні


(!) Однакові або дуже схожі роботи прийматися не будуть.
